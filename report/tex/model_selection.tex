%!TEX root = /Users/Daniel/Documents/Imperial/project/tevatron-higgs/report/report.tex

The performance of a neural network is highly dependent on both the number of nodes and the network topology. 
In theory by the Universal Approximation Theorem, an ANN with sufficiently many nodes arranged in single hidden layer is able to approximate an arbitrary decision boundary. However in practice deep neural networks can perform better, so a variety of sizes and topologies were investigated and evaluated. 

A commonly used criterion for measuring signal/background separation performance is the significance, $\frac{S(c)}{\sqrt{B(c)}}$ where $S(c)$ and $B(c)$ are the weighted number of signal and background events respectively, scoring above the signal acceptance cutoff $c$. Typically,  as a function of $ c \in (0,1)$, $\frac{S(c)}{\sqrt{B(c)}}$ has a maximum which can be used as a comparison.

Another evaluation parameter common in machine learning applications is the AUC, the area under the ROC (receiver operator characteristic) curve.
The ROC curve is the parametric plot of the true positive rate (tpr) against the false positive rate (fpr), parameterised by the cutoff.

\begin{figure}[h]
	\centering
	
	\begin{subfigure}{0.49\textwidth}
	      \includegraphics[width=\textwidth]{img/sig}
	      \caption{$\frac{S}{\sqrt{B}}$}
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
	      \includegraphics[width=\textwidth]{img/roc}
	      \caption{ROC curve of the classifier}
	\end{subfigure}
	
	\begin{subfigure}{0.5\textwidth}
	      \includegraphics[width=\textwidth]{img/sep}
	      \caption{Distribution of model scores for signal (red) and background (blue) events}
	\end{subfigure}

	\caption{Diagnostic plots for a train ANN with two layers of seven and six hidden nodes }
	\label{fig:label}
\end{figure}

In order to evaluate the reliance of the network on the (hypothesised) invariant dijet mass, the network was trained and evaluated both with and without $M_H$ over single layer configurations with between 1 and 50 hidden nodes.
As expected Figure~\ref{fig:mhcomp} shows that removing $M_H$ as a feature had a significant negative effect on the accuracy of the network.

\begin{figure}[htbp]
	\centering
	\begin{subfigure}{0.49\textwidth}
	      \includegraphics[width=\textwidth]{img/auc_1}
	      \caption{Area under ROC curve (AUC)}
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
		  \includegraphics[width=\textwidth]{img/sig_1}
		  \caption{Maximum significance}
	\end{subfigure}
	\caption{The ANN evaluated with (blue) and without (red) the invariant dijet mass $M_H$ as a feature }
	\label{fig:mhcomp}
\end{figure}

We also considered the effect of a second hidden layer on the discriminatory power of the ANN